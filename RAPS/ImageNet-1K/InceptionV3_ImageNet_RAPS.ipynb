{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# $\\alpha$=0.1",
   "id": "b5e422cce99f1cfd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before temperature - NLL: 1.082, ECE: 0.018\n",
      "Optimal temperature: 0.967\n",
      "After temperature - NLL: 1.073, ECE: 0.024\n",
      "RAPS Classification, Start!\n",
      "\n",
      "Running experiment 1/10...\n",
      "q_hat = 0.9593629121780396\n",
      "Total set size: 76860\n",
      "Total coverage sets: 22527\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 1: 3.0744\n",
      "Average Coverage Rate in runs 1: 0.90108\n",
      "\n",
      "Running experiment 2/10...\n",
      "q_hat = 0.9579761445522313\n",
      "Total set size: 75961\n",
      "Total coverage sets: 22502\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 2: 3.03844\n",
      "Average Coverage Rate in runs 2: 0.90008\n",
      "\n",
      "Running experiment 3/10...\n",
      "q_hat = 0.959210479259491\n",
      "Total set size: 76762\n",
      "Total coverage sets: 22547\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 3: 3.07048\n",
      "Average Coverage Rate in runs 3: 0.90188\n",
      "\n",
      "Running experiment 4/10...\n",
      "q_hat = 0.954694497585297\n",
      "Total set size: 75009\n",
      "Total coverage sets: 22410\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 4: 3.00036\n",
      "Average Coverage Rate in runs 4: 0.8964\n",
      "\n",
      "Running experiment 5/10...\n",
      "q_hat = 0.9561873733997346\n",
      "Total set size: 75431\n",
      "Total coverage sets: 22472\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 5: 3.01724\n",
      "Average Coverage Rate in runs 5: 0.89888\n",
      "\n",
      "Running experiment 6/10...\n",
      "q_hat = 0.9591769814491273\n",
      "Total set size: 76866\n",
      "Total coverage sets: 22556\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 6: 3.07464\n",
      "Average Coverage Rate in runs 6: 0.90224\n",
      "\n",
      "Running experiment 7/10...\n",
      "q_hat = 0.9543570101261141\n",
      "Total set size: 74404\n",
      "Total coverage sets: 22345\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 7: 2.97616\n",
      "Average Coverage Rate in runs 7: 0.8938\n",
      "\n",
      "Running experiment 8/10...\n",
      "q_hat = 0.9608968377113344\n",
      "Total set size: 77207\n",
      "Total coverage sets: 22550\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 8: 3.08828\n",
      "Average Coverage Rate in runs 8: 0.902\n",
      "\n",
      "Running experiment 9/10...\n",
      "q_hat = 0.9603015899658204\n",
      "Total set size: 77510\n",
      "Total coverage sets: 22573\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 9: 3.1004\n",
      "Average Coverage Rate in runs 9: 0.90292\n",
      "\n",
      "Running experiment 10/10...\n",
      "q_hat = 0.9565118074417116\n",
      "Total set size: 75687\n",
      "Total coverage sets: 22455\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 10: 3.02748\n",
      "Average Coverage Rate in runs 10: 0.8982\n",
      "\n",
      "Final Average Prediction Set Size: 3.05 ± 0.04\n",
      "Final Average Coverage: 0.8997 ± 0.0028\n"
     ]
    }
   ],
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms              \n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "from torchvision.models import Inception_V3_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "from src.temperature_scaling import ModelWithTemperature\n",
    "from src.raps import raps_test\n",
    "\n",
    "# load pre-trained model InceptionV3 and set mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1).to(device)\n",
    "\n",
    "#  Reprocess: Center Crop and then resize to 299*299\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.Resize(299), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "sorted_val_path = \"D:\\\\Download\\\\ImageNet-1K\\\\Validation_Set\\\\sorted_ImageNet_val\"\n",
    "dataset = ImageFolder(root=sorted_val_path, transform=data_transform)\n",
    "\n",
    "# Temperature Scaling\n",
    "model.eval() # only use output.logits of Inception's output\n",
    "subset_size = len(dataset) // 10\n",
    "indices = np.random.choice(len(dataset), subset_size, replace=False)\n",
    "subset_dataset = Subset(dataset, indices)\n",
    "train_loader = DataLoader(subset_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "model = ModelWithTemperature(model, temperature = 1.0).to(device)\n",
    "model.set_temperature(train_loader)\n",
    "model.eval()\n",
    "\n",
    "raps_test(model, dataset, device, num_runs=10, alpha=0.1, lambda_=0.2, k_reg=4)"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T03:14:35.801094Z",
     "start_time": "2025-04-30T03:14:04.623670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms              \n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "from torchvision.models import Inception_V3_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "from src.temperature_scaling import ModelWithTemperature\n",
    "from src.raps import raps_test\n",
    "\n",
    "# load pre-trained model InceptionV3 and set mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1).to(device)\n",
    "\n",
    "#  Reprocess: Center Crop and then resize to 299*299\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.Resize(299), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "sorted_val_path = \"D:\\\\Download\\\\ImageNet-1K\\\\Validation_Set\\\\sorted_ImageNet_val\"\n",
    "dataset = ImageFolder(root=sorted_val_path, transform=data_transform)\n",
    "\n",
    "# Temperature Scaling\n",
    "model.eval() # only use output.logits of Inception's output\n",
    "subset_size = len(dataset) // 10\n",
    "indices = np.random.choice(len(dataset), subset_size, replace=False)\n",
    "subset_dataset = Subset(dataset, indices)\n",
    "train_loader = DataLoader(subset_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "model = ModelWithTemperature(model, temperature = 1.0).to(device)\n",
    "model.set_temperature(train_loader)\n",
    "model.eval()\n"
   ],
   "id": "93b79adc3f5ac8a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before temperature - NLL: 1.057, ECE: 0.025\n",
      "Optimal temperature: 0.965\n",
      "After temperature - NLL: 1.047, ECE: 0.029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelWithTemperature(\n",
       "  (model): Inception3(\n",
       "    (Conv2d_1a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_2b_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv2d_3b_1x1): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (Conv2d_4a_3x3): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Mixed_5b): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5c): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_5d): InceptionA(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch5x5_2): BasicConv2d(\n",
       "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6a): InceptionB(\n",
       "      (branch3x3): BasicConv2d(\n",
       "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6b): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6c): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6d): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_6e): InceptionC(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7dbl_5): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (AuxLogits): InceptionAux(\n",
       "      (conv0): BasicConv2d(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (Mixed_7a): InceptionD(\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_3): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch7x7x3_4): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7b): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (Mixed_7c): InceptionE(\n",
       "      (branch1x1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3_2b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_1): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_2): BasicConv2d(\n",
       "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3a): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch3x3dbl_3b): BasicConv2d(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (branch_pool): BasicConv2d(\n",
       "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# $\\alpha$=0.2",
   "id": "becc8997e5830e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T03:43:51.173602Z",
     "start_time": "2025-04-30T03:18:16.190089Z"
    }
   },
   "cell_type": "code",
   "source": "raps_test(model, dataset, device, num_runs=10, alpha=0.2, lambda_=0.05, k_reg=9)",
   "id": "96e0183ee0fc61df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAPS Classification, Start!\n",
      "\n",
      "Running experiment 1/10...\n",
      "q_hat = 0.8089204430580139\n",
      "Total set size: 74876\n",
      "Total coverage sets: 20026\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 1: 2.99504\n",
      "Average Coverage Rate in runs 1: 0.80104\n",
      "\n",
      "Running experiment 2/10...\n",
      "q_hat = 0.8062701344490052\n",
      "Total set size: 72836\n",
      "Total coverage sets: 19881\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 2: 2.91344\n",
      "Average Coverage Rate in runs 2: 0.79524\n",
      "\n",
      "Running experiment 3/10...\n",
      "q_hat = 0.8126830577850341\n",
      "Total set size: 75266\n",
      "Total coverage sets: 20087\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 3: 3.01064\n",
      "Average Coverage Rate in runs 3: 0.80348\n",
      "\n",
      "Running experiment 4/10...\n",
      "q_hat = 0.8084321856498718\n",
      "Total set size: 75303\n",
      "Total coverage sets: 19945\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 4: 3.01212\n",
      "Average Coverage Rate in runs 4: 0.7978\n",
      "\n",
      "Running experiment 5/10...\n",
      "q_hat = 0.8089646339416504\n",
      "Total set size: 74680\n",
      "Total coverage sets: 19926\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 5: 2.9872\n",
      "Average Coverage Rate in runs 5: 0.79704\n",
      "\n",
      "Running experiment 6/10...\n",
      "q_hat = 0.8115634560585022\n",
      "Total set size: 75945\n",
      "Total coverage sets: 20153\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 6: 3.0378\n",
      "Average Coverage Rate in runs 6: 0.80612\n",
      "\n",
      "Running experiment 7/10...\n",
      "q_hat = 0.8079862952232361\n",
      "Total set size: 74425\n",
      "Total coverage sets: 19954\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 7: 2.977\n",
      "Average Coverage Rate in runs 7: 0.79816\n",
      "\n",
      "Running experiment 8/10...\n",
      "q_hat = 0.8129208326339722\n",
      "Total set size: 74930\n",
      "Total coverage sets: 20125\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 8: 2.9972\n",
      "Average Coverage Rate in runs 8: 0.805\n",
      "\n",
      "Running experiment 9/10...\n",
      "q_hat = 0.8106863737106323\n",
      "Total set size: 75657\n",
      "Total coverage sets: 20121\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 9: 3.02628\n",
      "Average Coverage Rate in runs 9: 0.80484\n",
      "\n",
      "Running experiment 10/10...\n",
      "q_hat = 0.8099501609802247\n",
      "Total set size: 75316\n",
      "Total coverage sets: 19997\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 10: 3.01264\n",
      "Average Coverage Rate in runs 10: 0.79988\n",
      "\n",
      "Final Average Prediction Set Size: 3.00 ± 0.03\n",
      "Final Average Coverage: 0.8009 ± 0.0036\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# $\\alpha$=0.05",
   "id": "8b4afe51a0bd97bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T22:44:33.808936Z",
     "start_time": "2025-04-16T22:19:00.966853Z"
    }
   },
   "cell_type": "code",
   "source": "raps_test(model, dataset, device, num_runs=10, alpha=0.05, lambda_=0.02, k_reg=15)",
   "id": "c1d7964b79748222",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAPS Classification, Start!\n",
      "\n",
      "Running experiment 1/10...\n",
      "q_hat = 0.9644444614648818\n",
      "Total set size: 296017\n",
      "Total coverage sets: 23815\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 1: 11.84068\n",
      "Average Coverage Rate in runs 1: 0.9526\n",
      "\n",
      "Running experiment 2/10...\n",
      "q_hat = 0.9632684409618377\n",
      "Total set size: 290781\n",
      "Total coverage sets: 23757\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 2: 11.63124\n",
      "Average Coverage Rate in runs 2: 0.95028\n",
      "\n",
      "Running experiment 3/10...\n",
      "q_hat = 0.9637184977531433\n",
      "Total set size: 293752\n",
      "Total coverage sets: 23808\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 3: 11.75008\n",
      "Average Coverage Rate in runs 3: 0.95232\n",
      "\n",
      "Running experiment 4/10...\n",
      "q_hat = 0.962581181526184\n",
      "Total set size: 291788\n",
      "Total coverage sets: 23754\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 4: 11.67152\n",
      "Average Coverage Rate in runs 4: 0.95016\n",
      "\n",
      "Running experiment 5/10...\n",
      "q_hat = 0.9615081757307052\n",
      "Total set size: 287551\n",
      "Total coverage sets: 23712\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 5: 11.50204\n",
      "Average Coverage Rate in runs 5: 0.94848\n",
      "\n",
      "Running experiment 6/10...\n",
      "q_hat = 0.9614523082971572\n",
      "Total set size: 287602\n",
      "Total coverage sets: 23730\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 6: 11.50408\n",
      "Average Coverage Rate in runs 6: 0.9492\n",
      "\n",
      "Running experiment 7/10...\n",
      "q_hat = 0.9601260274648666\n",
      "Total set size: 282241\n",
      "Total coverage sets: 23624\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 7: 11.28964\n",
      "Average Coverage Rate in runs 7: 0.94496\n",
      "\n",
      "Running experiment 8/10...\n",
      "q_hat = 0.9635475307703018\n",
      "Total set size: 290509\n",
      "Total coverage sets: 23756\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 8: 11.62036\n",
      "Average Coverage Rate in runs 8: 0.95024\n",
      "\n",
      "Running experiment 9/10...\n",
      "q_hat = 0.9642639428377151\n",
      "Total set size: 295825\n",
      "Total coverage sets: 23813\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 9: 11.833\n",
      "Average Coverage Rate in runs 9: 0.95252\n",
      "\n",
      "Running experiment 10/10...\n",
      "q_hat = 0.9621594458818435\n",
      "Total set size: 289746\n",
      "Total coverage sets: 23731\n",
      "Total samples amount: 25000\n",
      "Average Prediction Set Size After APS in runs 10: 11.58984\n",
      "Average Coverage Rate in runs 10: 0.94924\n",
      "\n",
      "Final Average Prediction Set Size: 11.62 ± 0.16\n",
      "Final Average Coverage: 0.9500 ± 0.0022\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Result  \n",
    "\n",
    "\n",
    "$\\alpha$=0.1  \n",
    "From the above test, following results can be collected :\n",
    "- Final Average Prediction Set Size: **3.05**\n",
    "- Final Average Coverage: **89.97%**\n",
    "\n",
    "$\\alpha$=0.2  \n",
    "From the above test, following results can be collected :\n",
    "- Final Average Prediction Set Size: **3.00**\n",
    "- Final Average Coverage: **80.09%**  \n",
    "\n",
    "$\\alpha$=0.05  \n",
    "From the above test, following results can be collected :\n",
    "- Final Average Prediction Set Size: **11.62**\n",
    "- Final Average Coverage: **95.00%**"
   ],
   "id": "d606af8e18ae7cdc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T22:44:33.824257Z",
     "start_time": "2025-04-16T22:44:33.809936Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b2ef3418a6e0783c",
   "outputs": [],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch2)",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
