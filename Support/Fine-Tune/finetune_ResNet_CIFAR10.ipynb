{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7628518c-7df7-4fae-9458-457b64b477d1",
   "metadata": {},
   "source": [
    "## Fine-Tune InceptionV3 on CIFAR10\n",
    "\n",
    "- CIFAR10 is a dataset with **10 classes**\n",
    "- InceptionV3 is a pre-trained model by ImageNet with **1000 classes**\n",
    "\n",
    "In order to output reliable prediction sets, we need to fine-tune the full-connected layer of model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9c1a1-b627-4361-a474-c2c95f8c5377",
   "metadata": {},
   "source": [
    "# 1. Load Model\n",
    "\n",
    "Generally, a model has two mode: train mode and evaluation mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4dcdc8e-6baa-40c7-ae9a-922213e498d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "Device count: 1\n",
      "Device name: NVIDIA GeForce RTX 3060 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiayang\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jiayang\\anaconda3\\envs\\pytorch2\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# check GPU status\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
    "\n",
    "# load pre-trained model InceptionV3 and set mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd6c70-e1ff-4270-9fa7-291c11db02ff",
   "metadata": {},
   "source": [
    "# 1. Fine-Tune prepare -- load train data set\n",
    "\n",
    "Load a CIFAR10 as the train data to fine-tune Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e0942aa-4ce8-48df-b00e-73fd4fb158e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\jiayang\\ipynb\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms               # include image preprocess tools\n",
    "from torchvision.datasets import CIFAR10, CIFAR100        # for loading images from Pytorch CIFAR\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# reprocess the images from CIFAR\n",
    "train_data_transform = transforms.Compose([ \n",
    "    transforms.RandomCrop(32, padding=4),  # 随机裁剪\n",
    "    transforms.RandomHorizontalFlip(),    \n",
    "    transforms.ToTensor(),          \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])  # normalize\n",
    "])\n",
    "\n",
    "data_transform = transforms.Compose([ \n",
    "    transforms.ToTensor(),          # transfer to tensor\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])  # normalize\n",
    "])\n",
    "\n",
    "# make sure CIFAR10 and CIFAR100 in the following adress:  THE_ADRESS_IN_OUTPUT/data\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "# load data set for training\n",
    "pre_train_dataset = CIFAR10(root=\"./data\", train=True, download=True,transform=train_data_transform)\n",
    "pre_test_dataset = CIFAR10(root=\"./data\", train=True, download=True, transform=data_transform)\n",
    "\n",
    "pre_train_loader = DataLoader(pre_train_dataset, batch_size=32, shuffle=True)\n",
    "pre_test_loader = DataLoader(pre_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8139a890-1c0d-4b6b-8bb6-715e402826ce",
   "metadata": {},
   "source": [
    "# 2.1 Fine-Tune\n",
    "\n",
    "- adjust output dimension from 1000 to 10\n",
    "- Freeze parameters in convolution layers and unlock parameters in fc layers\n",
    "- Train fc layer with CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff2f7c74-3c6e-46cb-b58b-117ec298d02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4493.9840\n",
      "Epoch [2/10], Loss: 4479.0306\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()        \u001b[38;5;66;03m# optimize parameters by back propagation\u001b[39;00m\n\u001b[0;32m     26\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()       \u001b[38;5;66;03m# update the parameters\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Test model after training\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim # optimizer\n",
    "\n",
    "# adjust output dimension 1000 --> 10\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "model = model.to(device)\n",
    "        \n",
    "# Train fc layer\n",
    "loss_function = nn.CrossEntropyLoss()   # define loss function\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.01)  # define optimize for fc layer\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0 # total loss in this epoch\n",
    "    for images, labels in pre_train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # front propagation\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # back propagation\n",
    "        optimizer.zero_grad()  # clear gradient\n",
    "        loss.backward()        # optimize parameters by back propagation\n",
    "        optimizer.step()       # update the parameters\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Test model after training\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in pre_test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        #  calculate the correct rate after training\n",
    "        _, predicted = torch.max(outputs, 1)  # outputs: [batch_size, num_classes]  --torch.max--> max_predicted_prob, max_predicted_prob_label\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9de3ce0-f6be-45f8-bc44-f11cd9668f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2007.7259\n",
      "Epoch [2/10], Loss: 1995.7321\n",
      "Epoch [3/10], Loss: 1991.3193\n",
      "Epoch [4/10], Loss: 1983.5468\n",
      "Epoch [5/10], Loss: 1966.1875\n",
      "Epoch [6/10], Loss: 1980.0112\n",
      "Epoch [7/10], Loss: 1949.0931\n",
      "Epoch [8/10], Loss: 1952.4309\n",
      "Epoch [9/10], Loss: 1960.0724\n",
      "Epoch [10/10], Loss: 1944.1561\n",
      "Test Accuracy: 59.83%\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0 # total loss in this epoch\n",
    "    for images, labels in pre_train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # front propagation\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # back propagation\n",
    "        optimizer.zero_grad()  # clear gradient\n",
    "        loss.backward()        # optimize parameters by back propagation\n",
    "        optimizer.step()       # update the parameters\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Test model after training\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in pre_test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        #  calculate the correct rate after training\n",
    "        _, predicted = torch.max(outputs, 1)  # outputs: [batch_size, num_classes]  --torch.max--> max_predicted_prob, max_predicted_prob_label\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43b300-0c88-4bd5-9bd8-e3f0c220bec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1d4d33d-8ae3-48e5-846b-67abeb3de514",
   "metadata": {},
   "source": [
    "# 1.5 Save fine-tuned Model\n",
    "\n",
    "Save current parameters and load the trained InceptionV3 in future by following steps:\n",
    "- model = models.inception_v3(pretrained=False)  # Noticed: pretrained=False!!!\n",
    "- model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "- model_path = \"C:\\Users\\jiayang\\ipynb\\trainedModel\\ResNet_50_CIFAR10.pth\"\n",
    "- model.load_state_dict(torch.load(model_path))\n",
    "- model.eval()\n",
    "- print(f\"Model loaded from {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c912d8b-77dc-4d9a-b22a-db9ca90b0851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output Shape: torch.Size([32, 10])\n",
      "Model saved to C:\\Users\\jiayang\\ipynb\\trainedModel\\ResNet_50_CIFAR10.pth\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(pre_test_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "outputs = model(images)\n",
    "print(\"Model Output Shape:\", outputs.shape)  # [batch_size, 10]\n",
    "\n",
    "# create directory\n",
    "save_dir = \"C:\\\\Users\\\\jiayang\\\\ipynb\\\\trainedModel\" # your save save path\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# save model data\n",
    "model_path = os.path.join(save_dir, \"ResNet_50_CIFAR10.pth\")\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac30261a-76b4-432a-8b5c-044e0f229d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from C:\\Users\\jiayang\\ipynb\\trainedModel\\ResNet_50_CIFAR10.pth\n",
      "Files already downloaded and verified\n",
      "\n",
      "Predictions on 25 images:\n",
      "Image 1:\n",
      "  Correct Label Index: 9 (truck)\n",
      "  Softmax Probabilities: [5.310959295456996e-06, 0.0049262274987995625, 7.131742313504219e-05, 0.002111848909407854, 0.0008120554266497493, 0.0012696977937594056, 1.0165010735363467e-06, 0.0001365264761261642, 1.342230007139733e-05, 0.9906526803970337]\n",
      "\n",
      "Image 2:\n",
      "  Correct Label Index: 6 (frog)\n",
      "  Softmax Probabilities: [8.79492836247664e-06, 1.0678945727704559e-06, 0.04288917034864426, 0.5719044208526611, 0.00030687625985592604, 0.0008152229129336774, 0.3839711844921112, 4.591902325046249e-05, 4.52903586847242e-05, 1.1959174116782378e-05]\n",
      "\n",
      "Image 3:\n",
      "  Correct Label Index: 5 (dog)\n",
      "  Softmax Probabilities: [0.0014166398905217648, 9.126879012910649e-05, 0.0005561573198065162, 0.0017897114157676697, 0.0008043101406656206, 0.9540363550186157, 3.3530730433994904e-05, 0.0008052687626332045, 0.03972446173429489, 0.0007422930793836713]\n",
      "\n",
      "Image 4:\n",
      "  Correct Label Index: 4 (deer)\n",
      "  Softmax Probabilities: [4.2027263589261565e-06, 9.960207592030201e-08, 0.002633065916597843, 0.00022206771245691925, 0.9970107078552246, 5.9631361182255205e-06, 2.3066286303219385e-05, 9.702067472971976e-05, 2.962522557936609e-06, 9.042329338626587e-07]\n",
      "\n",
      "Image 5:\n",
      "  Correct Label Index: 1 (automobile)\n",
      "  Softmax Probabilities: [0.00019835258717648685, 0.8981096148490906, 0.0004119669902138412, 0.0035490598529577255, 2.1442969227791764e-05, 0.0014985118759796023, 0.0004776777350343764, 0.00019936132594011724, 0.003485483583062887, 0.09204854816198349]\n",
      "\n",
      "Image 6:\n",
      "  Correct Label Index: 6 (frog)\n",
      "  Softmax Probabilities: [0.0001691797806415707, 3.066945964746992e-06, 0.0020782072097063065, 0.007779750507324934, 0.039137016981840134, 9.773686178959906e-05, 0.9500541090965271, 6.68118882458657e-05, 0.0005969343474134803, 1.7147620383184403e-05]\n",
      "\n",
      "Image 7:\n",
      "  Correct Label Index: 4 (deer)\n",
      "  Softmax Probabilities: [6.685667904093862e-05, 3.591503991628997e-05, 0.003133913269266486, 0.001055228873156011, 0.9908265471458435, 0.0037627711426466703, 2.2694512153975666e-05, 0.00102345016784966, 9.527549309495953e-07, 7.16639042366296e-05]\n",
      "\n",
      "Image 8:\n",
      "  Correct Label Index: 5 (dog)\n",
      "  Softmax Probabilities: [3.3702741347951815e-05, 8.990876813186333e-05, 0.0070396773517131805, 0.3226540982723236, 0.3617718517780304, 0.29052844643592834, 0.003200233681127429, 0.011382892727851868, 0.0004528822610154748, 0.0028462777845561504]\n",
      "\n",
      "Image 9:\n",
      "  Correct Label Index: 6 (frog)\n",
      "  Softmax Probabilities: [2.888910057663452e-05, 8.122212420857977e-06, 0.004138571210205555, 0.0008936820668168366, 0.0055198161862790585, 1.933970270329155e-05, 0.9887863397598267, 2.1614374418277293e-05, 4.123995040572481e-06, 0.0005794749595224857]\n",
      "\n",
      "Image 10:\n",
      "  Correct Label Index: 6 (frog)\n",
      "  Softmax Probabilities: [6.342294909700286e-06, 5.8252371673006564e-06, 0.588077962398529, 0.006718844641000032, 0.13841864466667175, 0.0014569462509825826, 0.26490092277526855, 0.0004106336273252964, 8.209499924305419e-07, 3.0115802474028897e-06]\n",
      "\n",
      "Image 11:\n",
      "  Correct Label Index: 4 (deer)\n",
      "  Softmax Probabilities: [0.0007234947988763452, 1.5947166502883192e-06, 0.0226530060172081, 0.00027834376669488847, 0.9738616943359375, 4.76223613077309e-05, 0.0007777025457471609, 0.00037401934969238937, 0.0012789162574335933, 3.6316303066996625e-06]\n",
      "\n",
      "Image 12:\n",
      "  Correct Label Index: 3 (cat)\n",
      "  Softmax Probabilities: [8.109663212962914e-06, 0.00012446990876924247, 0.00016476080054417253, 0.9911689758300781, 0.0008332529105246067, 0.005525257904082537, 0.0016728384653106332, 5.855357812833972e-05, 5.551147523874533e-07, 0.00044309155782684684]\n",
      "\n",
      "Image 13:\n",
      "  Correct Label Index: 6 (frog)\n",
      "  Softmax Probabilities: [1.4908155776538479e-07, 2.012933236983372e-06, 0.012296188622713089, 0.012908482924103737, 0.001772089395672083, 0.005923653952777386, 0.9669883847236633, 3.5278164432384074e-05, 7.208477086351195e-07, 7.309702050406486e-05]\n",
      "\n",
      "Image 14:\n",
      "  Correct Label Index: 3 (cat)\n",
      "  Softmax Probabilities: [4.6616667532362044e-05, 4.3076543079223484e-05, 0.0003460206789895892, 0.9954311847686768, 0.0005657417350448668, 0.0025183637626469135, 0.0001574343623360619, 3.912434294761624e-06, 0.00015905576583463699, 0.0007286964100785553]\n",
      "\n",
      "Image 15:\n",
      "  Correct Label Index: 0 (airplane)\n",
      "  Softmax Probabilities: [0.21983106434345245, 0.03516979515552521, 0.003998097497969866, 0.01343684270977974, 0.001218165853060782, 0.002276964485645294, 0.0005121516878716648, 0.0007559545338153839, 0.2799692451953888, 0.44283169507980347]\n",
      "\n",
      "Image 16:\n",
      "  Correct Label Index: 0 (airplane)\n",
      "  Softmax Probabilities: [0.5871424078941345, 3.732267578016035e-05, 0.3738143742084503, 0.0013990305596962571, 0.0005849729059264064, 0.00019106357649434358, 3.290279710199684e-05, 9.101329851546325e-06, 0.03654704988002777, 0.00024182428023777902]\n",
      "\n",
      "Image 17:\n",
      "  Correct Label Index: 7 (horse)\n",
      "  Softmax Probabilities: [9.02122410479933e-05, 0.00039030532934702933, 0.00015524910122621804, 0.0003619612252805382, 0.0012943244073539972, 0.0018855680245906115, 3.32828193450041e-07, 0.9932210445404053, 3.032465247088112e-05, 0.0025706822052598]\n",
      "\n",
      "Image 18:\n",
      "  Correct Label Index: 4 (deer)\n",
      "  Softmax Probabilities: [0.0012972981203347445, 0.000271918746875599, 0.24004988372325897, 0.12072823196649551, 0.5408199429512024, 0.0021115525159984827, 0.08442393690347672, 0.0014765521045774221, 1.8940492736874148e-05, 0.008801782503724098]\n",
      "\n",
      "Image 19:\n",
      "  Correct Label Index: 5 (dog)\n",
      "  Softmax Probabilities: [0.00622853497043252, 0.000193758838577196, 0.6737610697746277, 0.06590037792921066, 0.0664324089884758, 0.13965165615081787, 0.04227669537067413, 0.003132912330329418, 0.0021482184529304504, 0.0002743960067164153]\n",
      "\n",
      "Image 20:\n",
      "  Correct Label Index: 0 (airplane)\n",
      "  Softmax Probabilities: [0.7034299373626709, 0.00025346680195070803, 0.2816566228866577, 0.00693574408069253, 0.0031872657127678394, 0.0003086537471972406, 0.002749288221821189, 0.00036296158214099705, 0.000688048719894141, 0.0004280625144019723]\n",
      "\n",
      "Image 21:\n",
      "  Correct Label Index: 3 (cat)\n",
      "  Softmax Probabilities: [2.1470903448062018e-05, 4.9943249905481935e-05, 0.01320638507604599, 0.5795221328735352, 0.3070234954357147, 0.06848444044589996, 0.028167901560664177, 0.0035012701991945505, 7.770255251671188e-06, 1.5246160728565883e-05]\n",
      "\n",
      "Image 22:\n",
      "  Correct Label Index: 7 (horse)\n",
      "  Softmax Probabilities: [0.015782173722982407, 0.002257558284327388, 0.02182639203965664, 0.07779746502637863, 0.06790787726640701, 0.03555677831172943, 0.013247678987681866, 0.12359050661325455, 0.5928661823272705, 0.04916730523109436]\n",
      "\n",
      "Image 23:\n",
      "  Correct Label Index: 6 (frog)\n",
      "  Softmax Probabilities: [6.360474344546674e-06, 2.317697726539336e-05, 0.00284426286816597, 0.0016453113639727235, 0.014477843418717384, 0.00011142425501020625, 0.9807412028312683, 1.5319717931561172e-05, 4.18066956626717e-05, 9.328821033705026e-05]\n",
      "\n",
      "Image 24:\n",
      "  Correct Label Index: 4 (deer)\n",
      "  Softmax Probabilities: [0.001151521340943873, 2.489203507138882e-05, 0.21583259105682373, 0.047360844910144806, 0.492459237575531, 0.007850750349462032, 0.21681110560894012, 0.01822156086564064, 0.0002083128347294405, 7.916226604720578e-05]\n",
      "\n",
      "Image 25:\n",
      "  Correct Label Index: 5 (dog)\n",
      "  Softmax Probabilities: [1.4127825807008776e-06, 8.70864091950807e-09, 0.0003176057944074273, 0.9511433839797974, 4.528992940322496e-05, 0.04823495075106621, 0.00019807464559562504, 1.1325220157232252e-06, 5.80993146286346e-05, 5.978820638574689e-08]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(f\"Model loaded successfully from {model_path}\")\n",
    "\n",
    "dataset = CIFAR10(root=\"./data\", train=False, download=True, transform=data_transform)\n",
    "\n",
    "# randomly select 25 pictures\n",
    "subset_indices = np.random.choice(len(dataset), 25, replace=False)\n",
    "subset = torch.utils.data.Subset(dataset, subset_indices)\n",
    "loader = torch.utils.data.DataLoader(subset, batch_size=1, shuffle=False)\n",
    "\n",
    "# CIFAR-10 labels\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(\"\\nPredictions on 25 images:\")\n",
    "for i, (image, true_label) in enumerate(loader):\n",
    "    image, true_label = image.to(device), true_label.item()\n",
    "    \n",
    "    outputs = model(image)\n",
    "    softmax_probs = torch.softmax(outputs, dim=1).squeeze(0) \n",
    "    \n",
    "    print(f\"Image {i+1}:\")\n",
    "    print(f\"  Correct Label Index: {true_label} ({classes[true_label]})\")\n",
    "    print(f\"  Softmax Probabilities: {softmax_probs.tolist()}\") \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689621be-6aa8-40d6-a282-9ac36c02d1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch2)",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
