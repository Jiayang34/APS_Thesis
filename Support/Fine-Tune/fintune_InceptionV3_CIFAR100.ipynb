{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce47653-85cb-44e5-a0eb-3920ded67098",
   "metadata": {},
   "source": [
    "## Fine-Tune InceptionV3 on CIFAR100\n",
    "\n",
    "- CIFAR100 is a dataset with **100 classes**\n",
    "- InceptionV3 is a pre-trained model by ImageNet with **1000 classes**\n",
    "\n",
    "In order to output reliable prediction sets, we need to fine-tune the full-connected layer of model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1164fa01-de1a-4719-8cb2-fe733d2b77dd",
   "metadata": {},
   "source": [
    "# 1. Load Model\n",
    "\n",
    "Generally, a model has two mode: train mode and evaluation mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ebeb0a-4ff2-457e-849b-6293d00d5ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "Device count: 1\n",
      "Device name: NVIDIA GeForce RTX 3060 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# check GPU status\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
    "\n",
    "# load pre-trained model InceptionV3 and set mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.inception_v3(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb11c2b0-186c-4163-8c9d-40617a4ba3e0",
   "metadata": {},
   "source": [
    "# 1. Fine-Tune prepare -- load train data set\n",
    "\n",
    "Load a CIFAR100 as the train data to fine-tune Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527996ae-f268-4e03-b5f4-513e827397f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\jiayang\\ipynb\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms               # include image preprocess tools\n",
    "from torchvision.datasets import CIFAR10, CIFAR100        # for loading images from Pytorch CIFAR\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# reprocess the images from CIFAR\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # resize as the standard size of Inception\n",
    "    transforms.ToTensor(),          # transfer to tensor\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # normalize\n",
    "])\n",
    "\n",
    "# make sure CIFAR10 and CIFAR100 in the following adress:  THE_ADRESS_IN_OUTPUT/data\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "# load data set for training\n",
    "pre_train_dataset = CIFAR100(root=\"./data\", train=True, download=True,transform=data_transform)\n",
    "pre_test_dataset = CIFAR100(root=\"./data\", train=True, download=True, transform=data_transform)\n",
    "\n",
    "pre_train_loader = DataLoader(pre_train_dataset, batch_size=32, shuffle=True)\n",
    "pre_test_loader = DataLoader(pre_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5101bf2-dcd2-4098-8c16-2658dbce2de3",
   "metadata": {},
   "source": [
    "# 2.1 Fine-Tune\n",
    "\n",
    "- adjust output dimension from 1000 to 100\n",
    "- Freeze parameters in convolution layers and unlock parameters in fc layers\n",
    "- Train fc layer with CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8370e431-ae76-41e4-8c4a-de9ac5d950d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 4144.5217\n",
      "Epoch [2/5], Loss: 3313.7397\n",
      "Epoch [3/5], Loss: 3234.7987\n",
      "Epoch [4/5], Loss: 3227.6430\n",
      "Epoch [5/5], Loss: 3205.0869\n",
      "Test Accuracy: 59.82%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim # optimizer\n",
    "\n",
    "# adjust output dimension 1000 --> 100\n",
    "model.fc = nn.Linear(model.fc.in_features, 100)\n",
    "model = model.to(device)\n",
    "\n",
    "# Freeze parameters in convolution layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# unlock parameters in fc layers\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# Train fc layer\n",
    "loss_function = nn.CrossEntropyLoss()   # define loss function\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)  # define optimize for fc layer\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0 # total loss in this epoch\n",
    "    for images, labels in pre_train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # front propagation\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs.logits, labels)\n",
    "\n",
    "        # back propagation\n",
    "        optimizer.zero_grad()  # clear gradient\n",
    "        loss.backward()        # optimize parameters by back propagation\n",
    "        optimizer.step()       # update the parameters\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Test model after training\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in pre_test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        #  calculate the correct rate after training\n",
    "        _, predicted = torch.max(outputs, 1)  # outputs: [batch_size, num_classes]  --torch.max--> max_predicted_prob, max_predicted_prob_label\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7105371-f1d9-4809-964e-b9ff72022c9a",
   "metadata": {},
   "source": [
    "# 2.2 Check Fine-Tune Result\n",
    "\n",
    "We load a batch of test data to make a quick-test, which check the output dimension of the model after fine-tuning. The expected output is [32, 100]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beee1dd-8f6c-4506-be91-5fd7a7024fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(pre_test_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "outputs = model(images)\n",
    "print(\"Model Output Shape:\", outputs.shape)  # [batch_size, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261993a-5abb-4c19-9362-983702620788",
   "metadata": {},
   "source": [
    "# 1.5 Save fine-tuned Model\n",
    "\n",
    "Save current parameters and load the trained InceptionV3 in future by following steps:\n",
    "- model = models.inception_v3(pretrained=False)  # Noticed: pretrained=False!!!\n",
    "- model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "- model_path = \"C:\\Users\\jiayang\\ipynb\\trainedModel\\Inception_V3_CIFAR100.pth\"\n",
    "- model.load_state_dict(torch.load(model_path))\n",
    "- model.eval()\n",
    "- print(f\"Model loaded from {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eef5ed-68e2-49c5-9025-61e15bedddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(pre_test_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "outputs = model(images)\n",
    "print(\"Model Output Shape:\", outputs.shape)  # [batch_size, 100]\n",
    "\n",
    "# create directory\n",
    "save_dir = \"C:\\\\Users\\\\jiayang\\\\ipynb\\\\trainedModel\" # your save save path\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# save model data\n",
    "model_path = os.path.join(save_dir, \"Inception_V3_CIFAR100.pth\")\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
