{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7628518c-7df7-4fae-9458-457b64b477d1",
   "metadata": {},
   "source": [
    "## Fine-Tune InceptionV3 on CIFAR10\n",
    "\n",
    "- CIFAR10 is a dataset with **10 classes**\n",
    "- InceptionV3 is a pre-trained model by ImageNet with **1000 classes**\n",
    "\n",
    "In order to output reliable prediction sets, we need to fine-tune the full-connected layer of model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9c1a1-b627-4361-a474-c2c95f8c5377",
   "metadata": {},
   "source": [
    "# 1. Load Model\n",
    "\n",
    "Generally, a model has two mode: train mode and evaluation mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4dcdc8e-6baa-40c7-ae9a-922213e498d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "Device count: 1\n",
      "Device name: NVIDIA GeForce RTX 3060 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# check GPU status\n",
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
    "\n",
    "# load pre-trained model InceptionV3 and set mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.inception_v3(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd6c70-e1ff-4270-9fa7-291c11db02ff",
   "metadata": {},
   "source": [
    "# 1. Fine-Tune prepare -- load train data set\n",
    "\n",
    "Load a CIFAR10 as the train data to fine-tune Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0942aa-4ce8-48df-b00e-73fd4fb158e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\jiayang\\ipynb\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms               # include image preprocess tools\n",
    "from torchvision.datasets import CIFAR10, CIFAR100        # for loading images from Pytorch CIFAR\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# reprocess the images from CIFAR\n",
    "data_transform = transforms.Compose([ \n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),          # transfer to tensor\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # normalize\n",
    "])\n",
    "\n",
    "# make sure CIFAR10 and CIFAR100 in the following adress:  THE_ADRESS_IN_OUTPUT/data\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "# load data set for training\n",
    "pre_train_dataset = CIFAR10(root=\"./data\", train=True, download=True,transform=data_transform)\n",
    "pre_test_dataset = CIFAR10(root=\"./data\", train=True, download=True, transform=data_transform)\n",
    "\n",
    "pre_train_loader = DataLoader(pre_train_dataset, batch_size=32, shuffle=True)\n",
    "pre_test_loader = DataLoader(pre_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8139a890-1c0d-4b6b-8bb6-715e402826ce",
   "metadata": {},
   "source": [
    "# 2.1 Fine-Tune\n",
    "\n",
    "- adjust output dimension from 1000 to 10\n",
    "- Freeze parameters in convolution layers and unlock parameters in fc layers\n",
    "- Train fc layer with CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2f7c74-3c6e-46cb-b58b-117ec298d02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1627.7409\n",
      "Epoch [2/5], Loss: 1437.9260\n",
      "Epoch [3/5], Loss: 1433.9973\n",
      "Epoch [4/5], Loss: 1434.9058\n",
      "Epoch [5/5], Loss: 1431.0698\n",
      "Test Accuracy: 77.55%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim # optimizer\n",
    "\n",
    "# adjust output dimension 1000 --> 10\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "model = model.to(device)\n",
    "\n",
    "# Freeze parameters in convolution layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# unlock parameters in fc layers\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# Train fc layer\n",
    "loss_function = nn.CrossEntropyLoss()   # define loss function\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)  # define optimize for fc layer\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0 # total loss in this epoch\n",
    "    for images, labels in pre_train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # front propagation\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs.logits, labels)\n",
    "\n",
    "        # back propagation\n",
    "        optimizer.zero_grad()  # clear gradient\n",
    "        loss.backward()        # optimize parameters by back propagation\n",
    "        optimizer.step()       # update the parameters\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Test model after training\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in pre_test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        #  calculate the correct rate after training\n",
    "        _, predicted = torch.max(outputs, 1)  # outputs: [batch_size, num_classes]  --torch.max--> max_predicted_prob, max_predicted_prob_label\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e89882-f6b3-4778-bac7-c559d5266d96",
   "metadata": {},
   "source": [
    "# 2.2 Check Fine-Tune Result\n",
    "\n",
    "We load a batch of test data to make a quick-test, which check the output dimension of the model after fine-tuning. The expected output is [32, 10]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c16eb1-4c76-46d9-b3cc-39beadeb7805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output Shape: torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(pre_test_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "outputs = model(images)\n",
    "print(\"Model Output Shape:\", outputs.shape)  # [batch_size, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d4d33d-8ae3-48e5-846b-67abeb3de514",
   "metadata": {},
   "source": [
    "# 1.5 Save fine-tuned Model\n",
    "\n",
    "Save current parameters and load the trained InceptionV3 in future by following steps:\n",
    "- model = models.inception_v3(pretrained=False)  # Noticed: pretrained=False!!!\n",
    "- model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "- model_path = \"C:\\Users\\jiayang\\ipynb\\trainedModel\\Inception_V3_CIFAR10.pth\"\n",
    "- model.load_state_dict(torch.load(model_path))\n",
    "- model.eval()\n",
    "- print(f\"Model loaded from {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c912d8b-77dc-4d9a-b22a-db9ca90b0851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output Shape: torch.Size([32, 10])\n",
      "Model saved to C:\\Users\\jiayang\\ipynb\\trainedModel\\Inception_V3_CIFAR10.pth\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(pre_test_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "outputs = model(images)\n",
    "print(\"Model Output Shape:\", outputs.shape)  # [batch_size, 10]\n",
    "\n",
    "# create directory\n",
    "save_dir = \"C:\\\\Users\\\\jiayang\\\\ipynb\\\\trainedModel\" # your save save path\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# save model data\n",
    "model_path = os.path.join(save_dir, \"Inception_V3_CIFAR10.pth\")\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac30261a-76b4-432a-8b5c-044e0f229d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from C:\\Users\\jiayang\\ipynb\\trainedModel\\Inception_V3_CIFAR10.pth\n",
      "Files already downloaded and verified\n",
      "\n",
      "Predictions on 25 images:\n",
      "Image 1:\n",
      "  Correct Label Index: 3 (cat)\n",
      "  Softmax Probabilities: [0.1322980523109436, 0.11223164945840836, 0.12616108357906342, 0.38432055711746216, 0.017622916027903557, 0.0385405495762825, 0.14352673292160034, 0.022274896502494812, 0.0028038471937179565, 0.02021963521838188]\n",
      "\n",
      "Image 2:\n",
      "  Correct Label Index: 1 (automobile)\n",
      "  Softmax Probabilities: [0.08567936718463898, 0.09526278078556061, 0.45295819640159607, 0.10355601459741592, 0.057373542338609695, 0.08024773001670837, 0.08847623318433762, 0.013160191476345062, 0.014823965728282928, 0.008462033234536648]\n",
      "\n",
      "Image 3:\n",
      "  Correct Label Index: 6 (frog)\n",
      "  Softmax Probabilities: [0.11253733932971954, 0.0036756275221705437, 0.5619462132453918, 0.014866849407553673, 0.04043850302696228, 0.0012644536327570677, 0.23583929240703583, 0.01310797967016697, 0.015785101801156998, 0.0005386619595810771]\n",
      "\n",
      "Image 4:\n",
      "  Correct Label Index: 0 (airplane)\n",
      "  Softmax Probabilities: [0.7639381885528564, 0.0024347694125026464, 0.17131400108337402, 0.005362472962588072, 0.015616368502378464, 0.016221899539232254, 0.001804158091545105, 0.002054029144346714, 0.01716255024075508, 0.004091511946171522]\n",
      "\n",
      "Image 5:\n",
      "  Correct Label Index: 8 (ship)\n",
      "  Softmax Probabilities: [0.4755435287952423, 0.010882040485739708, 0.3114181458950043, 0.036454517394304276, 0.00574909383431077, 0.043871961534023285, 0.03641849383711815, 0.01988067477941513, 0.024665744975209236, 0.035115815699100494]\n",
      "\n",
      "Image 6:\n",
      "  Correct Label Index: 8 (ship)\n",
      "  Softmax Probabilities: [0.012804556638002396, 0.00021394755458459258, 0.8489373326301575, 0.06248172000050545, 0.03382972627878189, 0.01066248957067728, 0.007936402224004269, 0.020807355642318726, 0.0021830664481967688, 0.00014338945038616657]\n",
      "\n",
      "Image 7:\n",
      "  Correct Label Index: 7 (horse)\n",
      "  Softmax Probabilities: [0.0017813455779105425, 0.0017460568342357874, 0.030278710648417473, 0.06950788199901581, 0.014014328829944134, 0.4336002767086029, 0.0023602405562996864, 0.44097521901130676, 0.0004218258836772293, 0.005314073525369167]\n",
      "\n",
      "Image 8:\n",
      "  Correct Label Index: 0 (airplane)\n",
      "  Softmax Probabilities: [0.26664766669273376, 0.01193278655409813, 0.2130974680185318, 0.26394131779670715, 0.02007482759654522, 0.030859528109431267, 0.017888616770505905, 0.004639812279492617, 0.07457106560468674, 0.09634687006473541]\n",
      "\n",
      "Image 9:\n",
      "  Correct Label Index: 0 (airplane)\n",
      "  Softmax Probabilities: [0.028598297387361526, 0.005866633262485266, 0.6638258099555969, 0.1543131023645401, 0.009850571863353252, 0.04000256955623627, 0.030505124479532242, 0.005093039944767952, 0.04742942005395889, 0.014515395276248455]\n",
      "\n",
      "Image 10:\n",
      "  Correct Label Index: 6 (frog)\n",
      "  Softmax Probabilities: [0.01396439503878355, 0.0034771186765283346, 0.04720044136047363, 0.036432843655347824, 0.023601194843649864, 0.004002558533102274, 0.8449116349220276, 0.014322434552013874, 0.008633485063910484, 0.003453958546742797]\n",
      "\n",
      "Image 11:\n",
      "  Correct Label Index: 7 (horse)\n",
      "  Softmax Probabilities: [0.5644519925117493, 0.002304424997419119, 0.015566895715892315, 0.29002609848976135, 0.10714501887559891, 1.553907713969238e-05, 0.001466174959205091, 0.01821187324821949, 3.972174454247579e-06, 0.0008080225088633597]\n",
      "\n",
      "Image 12:\n",
      "  Correct Label Index: 2 (bird)\n",
      "  Softmax Probabilities: [0.0080255763605237, 0.0001488273701397702, 0.3772082030773163, 0.016555391252040863, 0.02612314000725746, 0.00197968864813447, 0.5685001015663147, 0.0012753697810694575, 0.00013273957301862538, 5.0983537221327424e-05]\n",
      "\n",
      "Image 13:\n",
      "  Correct Label Index: 0 (airplane)\n",
      "  Softmax Probabilities: [0.05040208622813225, 0.004965572617948055, 0.5131690502166748, 0.14195938408374786, 0.05894778296351433, 0.07801028341054916, 0.06835711747407913, 0.06037381291389465, 0.01200066413730383, 0.01181418914347887]\n",
      "\n",
      "Image 14:\n",
      "  Correct Label Index: 5 (dog)\n",
      "  Softmax Probabilities: [0.008059031330049038, 0.0004354229022283107, 0.4609786868095398, 0.20289982855319977, 0.01106370147317648, 0.29162755608558655, 0.00982074998319149, 0.002329232171177864, 0.011181585490703583, 0.0016041694907471538]\n",
      "\n",
      "Image 15:\n",
      "  Correct Label Index: 0 (airplane)\n",
      "  Softmax Probabilities: [0.3495117723941803, 0.0010207013692706823, 0.03547465428709984, 0.18405653536319733, 0.1258428990840912, 0.05051372945308685, 0.03955589234828949, 0.007155890576541424, 0.1965014934539795, 0.010366514325141907]\n",
      "\n",
      "Image 16:\n",
      "  Correct Label Index: 6 (frog)\n",
      "  Softmax Probabilities: [0.00010484835365787148, 1.365017033094773e-05, 0.4045840799808502, 0.03324781358242035, 0.03618880733847618, 0.003780043451115489, 0.519172191619873, 0.0029031396843492985, 1.9282558696431806e-06, 3.4832023629860487e-06]\n",
      "\n",
      "Image 17:\n",
      "  Correct Label Index: 8 (ship)\n",
      "  Softmax Probabilities: [0.9579920172691345, 0.00046576440217904747, 0.022976065054535866, 0.006256070453673601, 0.006876468192785978, 9.808137838263065e-05, 0.00017797306645661592, 0.002993333851918578, 0.0017751480918377638, 0.0003891885280609131]\n",
      "\n",
      "Image 18:\n",
      "  Correct Label Index: 8 (ship)\n",
      "  Softmax Probabilities: [0.37119826674461365, 0.0055116089060902596, 0.033078376203775406, 0.49341681599617004, 0.041818272322416306, 0.0008357295882888138, 0.0006570936529897153, 0.037868887186050415, 0.0006954026757739484, 0.014919526875019073]\n",
      "\n",
      "Image 19:\n",
      "  Correct Label Index: 3 (cat)\n",
      "  Softmax Probabilities: [0.0017415258334949613, 0.0008898207452148199, 0.11308436095714569, 0.3780490756034851, 0.0022264576982706785, 0.4030971825122833, 0.014085173606872559, 0.08456381410360336, 0.0011707566445693374, 0.0010918794432654977]\n",
      "\n",
      "Image 20:\n",
      "  Correct Label Index: 5 (dog)\n",
      "  Softmax Probabilities: [0.8977072834968567, 0.008694912306964397, 0.014264845289289951, 0.01276941318064928, 0.03692428767681122, 6.086541907279752e-05, 9.906103514367715e-05, 0.027822958305478096, 0.0008734068833291531, 0.0007829333189874887]\n",
      "\n",
      "Image 21:\n",
      "  Correct Label Index: 1 (automobile)\n",
      "  Softmax Probabilities: [0.0045328219421207905, 0.9746178388595581, 0.0011654539266601205, 0.007800690829753876, 0.0011063743149861693, 0.0016802714671939611, 0.000492364983074367, 0.00257398234680295, 0.0006846928736194968, 0.005345496349036694]\n",
      "\n",
      "Image 22:\n",
      "  Correct Label Index: 3 (cat)\n",
      "  Softmax Probabilities: [0.32085177302360535, 0.01279236190021038, 0.34295299649238586, 0.04770883172750473, 0.0863601416349411, 0.002742049051448703, 0.04579978436231613, 0.06305038928985596, 0.05968739464879036, 0.01805436983704567]\n",
      "\n",
      "Image 23:\n",
      "  Correct Label Index: 1 (automobile)\n",
      "  Softmax Probabilities: [0.18854589760303497, 0.30053651332855225, 0.04284895211458206, 0.020046379417181015, 0.0013312171213328838, 0.06710948050022125, 0.009983689524233341, 0.07146124541759491, 0.006451147608458996, 0.291685551404953]\n",
      "\n",
      "Image 24:\n",
      "  Correct Label Index: 3 (cat)\n",
      "  Softmax Probabilities: [0.20318961143493652, 0.004641937557607889, 0.5478390455245972, 0.05726952850818634, 0.03542788699269295, 0.031001288443803787, 0.09833014756441116, 0.01714451238512993, 0.0012730255257338285, 0.0038830770645290613]\n",
      "\n",
      "Image 25:\n",
      "  Correct Label Index: 8 (ship)\n",
      "  Softmax Probabilities: [0.1981978416442871, 0.07118066400289536, 0.5463656783103943, 0.019210074096918106, 0.021967852488160133, 0.016528161242604256, 0.007990656420588493, 0.08890368789434433, 0.004409109242260456, 0.025246301665902138]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(f\"Model loaded successfully from {model_path}\")\n",
    "\n",
    "dataset = CIFAR10(root=\"./data\", train=False, download=True, transform=data_transform)\n",
    "\n",
    "# randomly select 25 pictures\n",
    "subset_indices = np.random.choice(len(dataset), 25, replace=False)\n",
    "subset = torch.utils.data.Subset(dataset, subset_indices)\n",
    "loader = torch.utils.data.DataLoader(subset, batch_size=1, shuffle=False)\n",
    "\n",
    "# CIFAR-10 labels\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(\"\\nPredictions on 25 images:\")\n",
    "for i, (image, true_label) in enumerate(loader):\n",
    "    image, true_label = image.to(device), true_label.item()\n",
    "    \n",
    "    outputs = model(image)\n",
    "    softmax_probs = torch.softmax(outputs, dim=1).squeeze(0) \n",
    "    \n",
    "    print(f\"Image {i+1}:\")\n",
    "    print(f\"  Correct Label Index: {true_label} ({classes[true_label]})\")\n",
    "    print(f\"  Softmax Probabilities: {softmax_probs.tolist()}\") \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689621be-6aa8-40d6-a282-9ac36c02d1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
